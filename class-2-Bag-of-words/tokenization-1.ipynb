{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0df558",
   "metadata": {},
   "source": [
    "# nltk\n",
    "# spacy\n",
    "# transformers\n",
    "# Gensim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475258a9",
   "metadata": {},
   "source": [
    "# NLTK is Python’s API library for performing an array of tasks in human language. \n",
    "* It can perform a variety of operations on textual data, \n",
    "* such as classification, tokenization, \n",
    "* stemming, tagging, Leparsing, \n",
    "* semantic reasoning, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c538fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello NLP!', 'I love teaching.', 'Do you love learning?']\n"
     ]
    }
   ],
   "source": [
    "# Sentence tokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pprint import pprint\n",
    " \n",
    "text = \"Hello NLP! I love teaching. Do you love learning?\"\n",
    "result =sent_tokenize(text)\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e926bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'I',\n",
       " 'love',\n",
       " 'teaching',\n",
       " '.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'love',\n",
       " 'learning',\n",
       " '?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Hello NLP! I love teaching. Do you love learning?\"\n",
    "word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74137370",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "\n",
    "* spaCy is a popular library used in Natural Language Processing (NLP). \n",
    "* It’s an object-oriented library that helps with processing and analyzing text. \n",
    "* We can use spaCy to clean and prepare text, \n",
    "* break it into sentences and words and even extract useful information\n",
    "* from the text using its various tools and functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a337e5",
   "metadata": {},
   "source": [
    "* uv add pip\n",
    "* uv add spacy\n",
    "* python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c15adb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"NLP is amazing! spaCy makes it easy.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe883dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens:\n",
      "NLP\n",
      "is\n",
      "amazing\n",
      "!\n",
      "spaCy\n",
      "makes\n",
      "it\n",
      "easy\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Tokens:\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cf242bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'is', 'amazing', '!', 'spaCy', 'makes', 'it', 'easy', '.']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [token.text for token in doc]\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06229a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Tokens:\n",
      "['NLP is amazing!', 'spaCy makes it easy.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSentence Tokens:\")\n",
    "sentence_tokens = [sent.text for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6cc902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
